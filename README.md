# Matrix Multiplication Runtime Comparison

This project compares the runtime performance of two recursive matrix multiplication algorithms:  
- **DAC (Divide and Conquer)**  
- **Strassenâ€™s Algorithm**

It measures execution times for square matrices of different sizes and visualizes the results.

---

## ğŸ“Œ Features
- Generates random square matrices of sizes `2, 4, 8, ..., 256`.
- Multiplies them using **DAC** and **Strassen** algorithms.
- Measures execution time with configurable runs and recursion threshold.
- Plots results on a log-log scale for easy comparison.

---

## ğŸ“‚ Code Structure
- **`measure_times()`**  
  Runs multiplication for different sizes and methods, returning average runtimes.

- **Main Execution (`__main__`)**  
  - Calls `measure_times()` with default parameters.  
  - Plots runtime curves using Matplotlib.

---

## âš™ï¸ Requirements
Make sure you have Python 3.x installed along with the following libraries:

```bash
pip install matplotlib numpy
```

---

## ğŸ§© Notes

The script assumes that helper functions exist:

random_matrix(n) â†’ generates an n x n random matrix.

mult_with_padding(A, B, method, threshold) â†’ multiplies matrices using the selected method.

You can adjust parameters:

SIZES â†’ list of matrix sizes.

methods â†’ tuple of algorithms (dac, strassen).

runs â†’ number of repetitions for averaging runtime.

threshold â†’ recursion cutoff size for hybrid multiplication.

---

# ğŸ“–Background
Divide and Conquer (DAC)

Splits each matrix into 4 submatrices of size n/2 x n/2.

Recursively computes 8 multiplications of these submatrices.

Combines the results into the final matrix.

Has a time complexity of O(nÂ³), similar to the naive method, but with a recursive structure.

Strassenâ€™s Algorithm

An optimized divide-and-conquer method introduced by Volker Strassen in 1969.

Reduces the number of recursive multiplications from 8 to 7, at the cost of additional additions/subtractions.

Achieves a time complexity of about O(n^2.81), faster than standard O(nÂ³).

More efficient for large matrices, but overhead may make it slower for small ones.

Often implemented with a threshold: below a certain size, standard multiplication is used instead.

---
